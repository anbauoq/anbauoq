# Heyy, I am Marina

I work on understanding why language models sometimes get things wrong.

Iâ€™m currently a Data Science Intern at **ServiceTitan**, where I research hallucinations in LLM-powered voice assistants.

---

### ğŸŒŒ What Iâ€™m interested in
- Detecting subtle, confident hallucinations in LLMs  
- Pushing reasoning beyond surface-level pattern matching  
- Smarter evaluation methods
- Long-context modeling, latent variables, and deeper representations  
- Exploring the boundary between parroting and actual reasoning

---

### ğŸ¯ My goal  
Iâ€™d love to publish at **ICML** one day â€” not just for the paper, but to contribute meaningful insights into how and why these models break.

---

### ğŸ› ï¸ How Iâ€™m working toward it
- NLP, LLMs, and model interpretability  
- Studying model behavior, self-refinement, and failure patterns  
- Running lots of experiments and learning from messy outputs

---

### ğŸ“« Contact me
- Email: marina.igitkhanian@gmail.com
