# Heyy, I am Marina

I work on understanding why language models sometimes get things wrong.

I’m currently a Data Science Intern at **ServiceTitan**, where I research hallucinations in LLM-powered voice assistants.

---

### 🌌 What I’m interested in
- Detecting subtle, confident hallucinations in LLMs  
- Pushing reasoning beyond surface-level pattern matching  
- Smarter evaluation methods
- Long-context modeling, latent variables, and deeper representations  
- Exploring the boundary between parroting and actual reasoning

---

### 🎯 My goal  
I’d love to publish at **ICML** one day — not just for the paper, but to contribute meaningful insights into how and why these models break.

---

### 🛠️ How I’m working toward it
- NLP, LLMs, and model interpretability  
- Studying model behavior, self-refinement, and failure patterns  
- Running lots of experiments and learning from messy outputs

---

### 📫 Contact me
- Email: marina.igitkhanian@gmail.com
